{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module loads the data from data.py, creates a TensorFlow/Keras model from model.py, trains the model on the data, and then saves the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am settings\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'settings' has no attribute 'DATA_PATH'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e34508191c6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msettings\u001b[0m    \u001b[0;31m# Use the custom settings.py file for default parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workshop/unet/medical-decathlon/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \"\"\"\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0margparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workshop/unet/medical-decathlon/argparser.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     add_help=True, formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m parser.add_argument(\"--data_path\", default=settings.DATA_PATH,\n\u001b[0m\u001b[1;32m     34\u001b[0m                     help=\"the path to the data\")\n\u001b[1;32m     35\u001b[0m parser.add_argument(\"--data_filename\", default=settings.DATA_FILENAME,\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'settings' has no attribute 'DATA_PATH'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf # conda install -c anaconda tensorflow\n",
    "import time\n",
    "import os\n",
    "import settings    # Use the custom settings.py file for default parameters\n",
    "\n",
    "from model import load_model, get_callbacks, evaluate_model\n",
    "from data import load_data\n",
    "\n",
    "from argparser import args\n",
    "\n",
    "if args.keras_api:\n",
    "    import keras as K\n",
    "else:\n",
    "    from tensorflow import keras as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For best CPU speed set the number of intra and inter threads to take advantage of multi-core systems.\n",
    "See https://github.com/intel/mkl-dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(intra_op_parallelism_threads=args.num_threads,\n",
    "                        inter_op_parallelism_threads=args.num_inter_threads)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "\n",
    "def train_and_predict(data_path, data_filename, batch_size, n_epoch):\n",
    "    \"\"\"\n",
    "    Create a model, load the data, and train it.\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Step 1: Load the data\n",
    "    \"\"\"\n",
    "    hdf5_filename = os.path.join(data_path, data_filename)\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Loading the data from HDF5 file ...\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    imgs_train, msks_train, imgs_validation, msks_validation = \\\n",
    "        load_data(hdf5_filename)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Creating and compiling model ...\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    \"\"\"\n",
    "    Step 2: Define the model\n",
    "    \"\"\"\n",
    "    model = load_model(imgs_train.shape, msks_train.shape)\n",
    "\n",
    "    model_filename, model_callbacks = get_callbacks()\n",
    "\n",
    "    \"\"\"\n",
    "    Step 3: Train the model on the data\n",
    "    \"\"\"\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Fitting model with training data ...\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    history = model.fit(imgs_train, msks_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=n_epoch,\n",
    "                        validation_data=(imgs_validation, msks_validation),\n",
    "                        verbose=1, shuffle=\"batch\",\n",
    "                        callbacks=model_callbacks)\n",
    "\n",
    "    # Append training log\n",
    "    # with open(\"training.log\",\"a+\") as fp:\n",
    "    #     fp.write(\"{}: {}\\n\".format(datetime.datetime.now(),\n",
    "    #                              history.history[\"val_dice_coef\"]))\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Step 4: Evaluate the best model\n",
    "    \"\"\"\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Loading the best trained model ...\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    model = evaluate_model(model_filename, imgs_validation, msks_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some details on the processor of our system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:          x86_64\r\n",
      "CPU op-mode(s):        32-bit, 64-bit\r\n",
      "Byte Order:            Little Endian\r\n",
      "CPU(s):                16\r\n",
      "On-line CPU(s) list:   0-15\r\n",
      "Thread(s) per core:    2\r\n",
      "Core(s) per socket:    8\r\n",
      "Socket(s):             1\r\n",
      "NUMA node(s):          1\r\n",
      "Vendor ID:             GenuineIntel\r\n",
      "CPU family:            6\r\n",
      "Model:                 85\r\n",
      "Model name:            Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz\r\n",
      "Stepping:              4\r\n",
      "CPU MHz:               3404.926\r\n",
      "BogoMIPS:              6000.00\r\n",
      "Hypervisor vendor:     KVM\r\n",
      "Virtualization type:   full\r\n",
      "L1d cache:             32K\r\n",
      "L1i cache:             32K\r\n",
      "L2 cache:              1024K\r\n",
      "L3 cache:              25344K\r\n",
      "NUMA node0 CPU(s):     0-15\r\n",
      "Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves ida arat pku ospke\r\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(\"Started script on {}\".format(datetime.datetime.now()))\n",
    "\n",
    "print(\"args = {}\".format(args))\n",
    "os.system(\"uname -a\")\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "start_time = time.time()\n",
    "\n",
    "train_and_predict(args.data_path, args.data_filename,\n",
    "                      args.batch_size, args.epochs)\n",
    "\n",
    "print(\n",
    "    \"Total time elapsed for program = {} seconds\".format(\n",
    "        time.time() -\n",
    "        start_time))\n",
    "print(\"Stopped script on {}\".format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inference_examples.py  \\\n",
    "        --data_path $DECATHLON_DIR/${IMG_SIZE}x${IMG_SIZE} \\\n",
    "        --data_filename $MODEL_OUTPUT_FILENAME \\\n",
    "        --output_path $MODEL_OUTPUT_DIR \\\n",
    "        --inference_filename $INFERENCE_FILENAME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "SPDX-License-Identifier: EPL-2.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
